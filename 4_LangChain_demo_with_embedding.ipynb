{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9pLBWSf5l59",
    "outputId": "48e32cc7-e02a-477e-b0b3-fe39b1d7c0a5"
   },
   "source": [
    "!pip install openai\n",
    "!pip install --upgrade langchain\n",
    "!pip install langchain pypdf2 openai chromadb tiktoken docx2txt\n",
    "!pip install pypdf\n",
    "!pip install pypdf2\n",
    "!pip install unstructured\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCjbjp0I7lBW"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qiYYvPF9_4zh"
   },
   "outputs": [],
   "source": [
    "# The embedding engine that will convert our text to vectors\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "#llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Qly4fKh_yoD"
   },
   "outputs": [],
   "source": [
    "# The vectorstore we'll be using\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# The LangChain component we'll use to get the documents\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UgkYHCu07qUR",
    "outputId": "99cf7e4b-65cb-4ebc-8974-45856329bf84"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "openai_api_key = ''\n",
    "pdf_loader = OnlinePDFLoader(\"https://example-files.online-convert.com/document/pdf/example_complex.pdf\")\n",
    "doc = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1IFMjTz97M0",
    "outputId": "5b383ab2-3159-4545-bd53-8985a3d02fe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document\n",
      "You have 3833 characters in that document\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(doc)} document\")\n",
    "print (f\"You have {len(doc[0].page_content)} characters in that document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjdthvu0-E0k"
   },
   "source": [
    "Now let's split our document into small pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUl3RaSA-LgM"
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3qkoah0_Ai7",
    "outputId": "d1fbf699-30fe-460a-bcd7-52bcd3f3ea36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 5 documents that have an average of 906 characters (smaller pieces)\n"
     ]
    }
   ],
   "source": [
    "#Get the total number of characters so that we can see the average later\n",
    "num_total_characters = sum([len(x.page_content) for x in docs])\n",
    "print (f\"Now you have {len(docs)} documents that have an average of {num_total_characters / len(docs):,.0f} characters (smaller pieces)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scEBB2ocCOkM"
   },
   "outputs": [],
   "source": [
    "# Get your embeddings engine ready\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "#Embed your documents and combine wth the raw text in a pseudo db. Note: this\n",
    "#will make a API call to OpenAI\n",
    "docsearch = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMTR3JX1IPbh"
   },
   "source": [
    "Create your retrieval chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zS_iPEMIbla"
   },
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(temperature=0, openai_api_key=openai_api_key), chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doJc6TbK35qn"
   },
   "source": [
    "Now, its time to ask questions. The retriever will go get the similar documents and combine with your question for the LLM to reason through.\n",
    "\n",
    "**Note: It might not seem like much, but the magic here is that we didn't have to pass in our original full document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Y7g3_MzD4ejt",
    "outputId": "0b860701-df38-4b95-9783-599375ebdeee"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' The name John Doe has been referenced in popular culture in the Frank Capra film Meet John Doe and the 2002 American television series of the same name.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"How has the name John Doe been referenced in popular culture?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "uS5SPJYrtdU1",
    "outputId": "22f7ce07-c44b-42bc-c764-e60f4ffb33b7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' PDF'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"What is the document file type being referenced?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "RHvlxZvjuUCX",
    "outputId": "f23a4692-d0f5-4968-c609-db851048abad"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' 1.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"What is the version of the document being referenced being referenced?\"\n",
    "qa.run(query)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
